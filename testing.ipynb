{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNJA+EjgiCU98Z1Dk0RyS8m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Heart Segmentation Project"],"metadata":{"id":"sPfEcGrOst4O"}},{"cell_type":"markdown","source":["## Introduction\n","This project focuses on segmenting different parts of the heart using deep learning techniques. We will use a dataset of medical images and train a model to accurately segment regions of interest.\n","\n","### Objectives\n","- Segment the right ventricle (RV)\n","- Segment the myocardium (MYO)\n","- Segment the left ventricle (LV)"],"metadata":{"id":"LJmnXS5Gsuv2"}},{"cell_type":"markdown","source":["## Dependencies Import and Exploration\n","This section covers the initial steps of importing every dependency for data manipulation, transformation, visualization, model handling, and other utilities. It also includes a command to mount Google Drive for accessing files in a Google Colab environment.\n","\n","1. `gc` and `gc.collect()`: Imports the garbage collection module and calls the `collect` method to free up memory.\n","2. `random`: Provides functions for generating random numbers and making random selections.\n","3. `torchvision.transforms as t`: Imports the `transforms` module from `torchvision`, which provides image transformation functions.\n","4. `IPython.display import Image as IPImage`: Imports the `Image` class from `IPython.display` for displaying images in Jupyter notebooks.\n","5. `torch`: The main library for PyTorch, used for building and training neural networks.\n","6. `sys`: Provides access to system-specific parameters and functions.\n","7. `os`: Provides functions for interacting with the operating system.\n","8. `pandas as pd`: Imports pandas, a data manipulation and analysis library.\n","9. `matplotlib.pyplot as plt`: Imports the plotting library for creating static, animated, and interactive visualizations.\n","10. `numpy as np`: Imports NumPy, a library for numerical operations on arrays.\n","11. `torch.nn as nn`: Imports the neural network module from PyTorch.\n","12. `nibabel as nib`: Imports nibabel for reading and writing medical image formats.\n","13. `torch.nn.functional as F`: Imports functional operations for neural networks from PyTorch.\n","14. `pickle`: Provides functions for serializing and deserializing Python objects.\n","15. `torch.utils.data import Dataset, DataLoader, random_split`: Imports data handling classes from PyTorch.\n","16. `PIL import Image`: Imports the Python Imaging Library (PIL) for image processing.\n","17. `imageio`: Provides functions for reading and writing images.\n","18. `time`: Provides functions for time-related operations.\n","19. `torchvision.models as models`: Imports pre-trained models from `torchvision`.\n","20. `cv2`: Imports OpenCV for computer vision tasks.\n","21. `statistics import mode`: Imports the mode function for statistical operations.\n","22. `google.colab import drive` and `drive.mount('/content/gdrive')`: Imports the Google Drive module from Google Colab and mounts the Google Drive for accessing files."],"metadata":{"id":"4l3hvXyLsxnk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Csj4OZWzLTXo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720859367951,"user_tz":-420,"elapsed":17496,"user":{"displayName":"Julian Alex","userId":"18141133109877911893"}},"outputId":"e5758d82-3053-400c-b8af-e92756193950"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (4.0.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.25.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (67.7.2)\n"]}],"source":["!pip install nibabel"]},{"cell_type":"code","source":["import gc\n","gc.collect()\n","import random\n","from torchvision.transforms import v2 as t\n","from IPython.display import Image as IPImage\n","import random\n","import torch\n","import sys\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import nibabel as nib\n","import torch.nn.functional as F\n","from torchvision.transforms import v2 as t\n","import random\n","import pickle\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from PIL import Image\n","import imageio\n","import time\n","from IPython.display import Image as IPImage\n","import gc\n","import torchvision.models as models\n","import cv2\n","from statistics import mode\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0x3ONY-kfLVT","executionInfo":{"status":"ok","timestamp":1720859418253,"user_tz":-420,"elapsed":50305,"user":{"displayName":"Julian Alex","userId":"18141133109877911893"}},"outputId":"2edfdb67-1bb2-466f-96ca-32bf50484eda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["## import numpy as np\n","sys.path.append('/content/gdrive/MyDrive/finalproject-ruangguru')\n","import functs as m\n","from loss_function import Adaptive_tvMF_DiceLoss\n","from unet_model import U_Net\n","# device = device = xm.xla_device()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device, torch.cuda.device_count())\n","def report_gpu():\n","    print(torch.cuda.list_gpu_processes())\n","    gc.collect()\n","    torch.cuda.empty_cache()"],"metadata":{"id":"1F17gs7qfMGb","executionInfo":{"status":"ok","timestamp":1720859421162,"user_tz":-420,"elapsed":2912,"user":{"displayName":"Julian Alex","userId":"18141133109877911893"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1dacaef-ff01-4f95-d841-715cc9d16327"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda 1\n"]}]},{"cell_type":"markdown","source":["## Model Selection\n","\n","In this project, we utilize two different neural network architectures for heart segmentation: DenseNet-121 and MobileNetV2. These models have been chosen due to their balance between accuracy and computational efficiency.\n","\n","### DenseNet-121\n","> DenseNet-121 is a densely connected convolutional network architecture that improves the flow of information and gradients throughout the network, making it easier to train. It is known for achieving high performance on image classification tasks.\n","\n","### MobileNetV2\n","> MobileNetV2 is a lightweight convolutional neural network designed for mobile and edge devices. Despite its smaller size and lower computational cost, it can achieve competitive accuracy. This model is less explored for the given dataset, hence its inclusion in this project aims to evaluate its performance in heart MRI segmentation.\n","\n","## Model Loading\n","\n","> Here, we load the pre-trained weights for both DenseNet-121 and MobileNetV2 models. These weights are fine-tuned on our specific dataset to perform the task of heart segmentation."],"metadata":{"id":"YUsPCp9ztFGJ"}},{"cell_type":"code","source":["data = m.load_train_data('/content/gdrive/MyDrive/finalproject-ruangguru/result1/')\n","data_mobile = m.load_train_data('/content/gdrive/MyDrive/finalproject-ruangguru/result-mobilenet/results/')"],"metadata":{"id":"g_9BYfWR7umh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_test = m.ACDC_2D_Dataset(\n","    \"/content/gdrive/MyDrive/finalproject-ruangguru/test.csv\",\n","    \"/content/gdrive/MyDrive/finalproject-ruangguru/ACDC\",\n","    joint_transform = None,\n","    image_transform = None,\n","    train=False\n",")"],"metadata":{"id":"QnDFwXJ08Dgx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Optimizer and Loss Function\n","\n","We use the Adam optimizer with a learning rate of 0.0005 and a weight decay of 0.0001 for regularization. The loss function is customized to handle the imbalances in the segmentation labels, with equal weighting for each class (left ventricle, myocardium, and ventricle)."],"metadata":{"id":"eVI-0Fp8tWE6"}},{"cell_type":"code","source":["model = m.TrainedAutoencoder('densenet121',4)\n","model.load_state_dict(data['model_state_dict'])\n","\n","model_mobile = m.TrainedAutoencoder('mobilenet_v2',4)\n","model_mobile.load_state_dict(data_mobile['model_state_dict'])\n","\n","optim = torch.optim.Adam(model.parameters(), lr= 0.0005, weight_decay = 0.0001)\n","loss = m.CustomLoss(weights = [1.0, 1.0, 1.0])\n","metric = [m.ClassDice(channel = 1), m.ClassDice(channel = 2), m.ClassDice(channel=3)]"],"metadata":{"id":"EO8MPVaO8LwK","executionInfo":{"status":"ok","timestamp":1720859474709,"user_tz":-420,"elapsed":693,"user":{"displayName":"Julian Alex","userId":"18141133109877911893"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b33c447d-284b-4023-fc65-23ca19789e8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n","100%|██████████| 30.8M/30.8M [00:00<00:00, 116MB/s]\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 97.3MB/s]\n"]}]},{"cell_type":"markdown","source":["## Model Testing\n","\n","The test function evaluates the performance of both DenseNet-121 and MobileNetV2 models on the test dataset. The metrics used for evaluation include class-specific Dice scores, which measure the overlap between the predicted and ground truth segmentations."],"metadata":{"id":"g1xMP6zOtbfx"}},{"cell_type":"code","source":["loss, metric = m.test(DATASET = data_test,\n","                      MODEL = model,\n","                      MODEL2 = model_mobile,\n","                      LOSS = loss,\n","                      METRICS = metric,\n","                      SAVE_LOC = '/content/gdrive/MyDrive/finalproject-ruangguru/result1-test2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BClhsiac8ZEQ","outputId":"c560ca4a-6172-46c7-f725-979d6b76beda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"cjeOk7Ummdod"},"execution_count":null,"outputs":[]}]}